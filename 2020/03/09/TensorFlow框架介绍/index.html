<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/assets/avatar_16x16.jpg?v=2.1.1" type="image/png" sizes="16x16"><link rel="icon" href="/assets/avatar_32x32.jpg?v=2.1.1" type="image/png" sizes="32x32"><meta name="description" content="TF 数据流图                           加法案例       123456789101112131415161718192021import tensorflow as tfdef tensorflow_demo():    # 实现加法    a_t &#x3D; tf.constant(2)    b_t &#x3D; tf.constant(3)    c_t">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow框架介绍">
<meta property="og:url" content="https://blog.zyuanlee.cn/2020/03/09/TensorFlow%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D/index.html">
<meta property="og:site_name" content="Pandalzy&#39;s Blog">
<meta property="og:description" content="TF 数据流图                           加法案例       123456789101112131415161718192021import tensorflow as tfdef tensorflow_demo():    # 实现加法    a_t &#x3D; tf.constant(2)    b_t &#x3D; tf.constant(3)    c_t">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200305181919.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200308221528.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309190938.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309191005.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309191030.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309191053.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309191853.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309191942.png">
<meta property="article:published_time" content="2020-03-09T13:47:11.000Z">
<meta property="article:modified_time" content="2021-06-27T00:34:28.402Z">
<meta property="article:author" content="Pandalzy">
<meta property="article:tag" content="TensorFlow">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200305181919.png"><title>TensorFlow框架介绍 | Pandalzy's Blog</title><link ref="canonical" href="https://blog.zyuanlee.cn/2020/03/09/TensorFlow%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.1.1"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":true},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"carbon","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/about/"><span class="header-nav-menu-item__icon"><i class="fas fa-address-card"></i></span><span class="header-nav-menu-item__text">关于</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/friends/"><span class="header-nav-menu-item__icon"><i class="fas fa-user-friends"></i></span><span class="header-nav-menu-item__text">友链</span></a></div></div><div class="header-nav-search"><span class="header-nav-search__icon"><i class="fas fa-search"></i></span><span class="header-nav-search__text">搜索</span></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Pandalzy's Blog</div><div class="header-banner-info__subtitle">Stay hungry, stay foolish.</div></div><div class="header-banner-arrow"><div class="header-banner-arrow__icon"><i class="fas fa-angle-down"></i></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">TensorFlow框架介绍</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2020-03-09</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-06-27</span></span></div></header><div class="post-body">
        <h2 id="TF-数据流图"   >
          <a href="#TF-数据流图" class="heading-link"><i class="fas fa-link"></i></a>TF 数据流图</h2>
      
        <h3 id="加法案例"   >
          <a href="#加法案例" class="heading-link"><i class="fas fa-link"></i></a>加法案例</h3>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensorflow_demo</span>():</span></span><br><span class="line">    <span class="comment"># 实现加法</span></span><br><span class="line">    a_t = tf.constant(<span class="number">2</span>)</span><br><span class="line">    b_t = tf.constant(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    c_t = a_t + b_t</span><br><span class="line">    <span class="built_in">print</span>(c_t)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开启会话</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        c_t_value = sess.run(c_t)</span><br><span class="line">        <span class="built_in">print</span>(c_t_value)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tensorflow_demo()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensor(&quot;add:0&quot;, shape=(), dtype=int32)</span></span><br><span class="line"><span class="comment"># 5</span></span><br></pre></td></tr></table></div></figure>

<span id="more"></span>


        <h3 id="TF-结构分析"   >
          <a href="#TF-结构分析" class="heading-link"><i class="fas fa-link"></i></a>TF 结构分析</h3>
      <ul>
<li>一个构建图阶段<ul>
<li>流程图：定义数据（张量 Tensor）和操作（节点 op）</li>
</ul>
</li>
<li>一个执行图阶段<ul>
<li>调用各方资源，讲定义好的数据和操作运行起来</li>
</ul>
</li>
</ul>

        <h4 id="数据流图介绍"   >
          <a href="#数据流图介绍" class="heading-link"><i class="fas fa-link"></i></a>数据流图介绍</h4>
      <p>Tensor-张量-数据</p>
<p>Flow-流动</p>

        <h2 id="图与-TensorBoard"   >
          <a href="#图与-TensorBoard" class="heading-link"><i class="fas fa-link"></i></a>图与 TensorBoard</h2>
      
        <h3 id="图结构"   >
          <a href="#图结构" class="heading-link"><i class="fas fa-link"></i></a>图结构</h3>
      <p>数据（Tensor）+操作（Operation）</p>

        <h3 id="相关操作"   >
          <a href="#相关操作" class="heading-link"><i class="fas fa-link"></i></a>相关操作</h3>
      <ul>
<li><p>默认图</p>
<ul>
<li><p>调用方法<code>tf.get_default_graph()</code></p>
</li>
<li><p>查看属性<code>.graph</code></p>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">graph_demo</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    图的演示</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    a_t = tf.constant(<span class="number">2</span>)</span><br><span class="line">    b_t = tf.constant(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    c_t = a_t + b_t</span><br><span class="line">    <span class="built_in">print</span>(c_t)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查看默认图</span></span><br><span class="line">    default_g = tf.get_default_graph()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;图方法&#x27;</span>, default_g)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;图属性&#x27;</span>, c_t.graph)</span><br><span class="line">    <span class="comment"># 开启会话</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        c_t_value = sess.run(c_t)</span><br><span class="line">        <span class="built_in">print</span>(c_t_value)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;图属性&#x27;</span>, sess.graph)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    graph_demo()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensor(&quot;add:0&quot;, shape=(), dtype=int32)</span></span><br><span class="line"><span class="comment"># 图方法 &lt;tensorflow.python.framework.ops.Graph object at 0x000001C855C96E88&gt;</span></span><br><span class="line"><span class="comment"># 图属性 &lt;tensorflow.python.framework.ops.Graph object at 0x000001C855C96E88&gt;</span></span><br><span class="line"><span class="comment"># 5</span></span><br><span class="line"><span class="comment"># 图属性 &lt;tensorflow.python.framework.ops.Graph object at 0x000001C855C96E88&gt;</span></span><br></pre></td></tr></table></div></figure>

<ul>
<li>创建图</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">new_g = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> new_g.as_default():</span><br><span class="line">    <span class="comment"># 定义数据和操作</span></span><br></pre></td></tr></table></div></figure>

<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">new_g = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> new_g.as_default():</span><br><span class="line">    a_new = tf.constant(<span class="number">20</span>)</span><br><span class="line">    b_new = tf.constant(<span class="number">30</span>)</span><br><span class="line">    c_new = a_new + b_new</span><br><span class="line">    <span class="built_in">print</span>(c_new)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=new_g) <span class="keyword">as</span> sess:</span><br><span class="line">    c_new_value = sess.run(c_new)</span><br><span class="line">    <span class="built_in">print</span>(c_new_value)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;创建图&#x27;</span>, sess.graph)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensor(&quot;add:0&quot;, shape=(), dtype=int32)</span></span><br><span class="line"><span class="comment"># 50</span></span><br><span class="line"><span class="comment"># 创建图 &lt;tensorflow.python.framework.ops.Graph object at 0x000001E7C282D5C8&gt;</span></span><br></pre></td></tr></table></div></figure>


        <h3 id="可视化-TensorBoard"   >
          <a href="#可视化-TensorBoard" class="heading-link"><i class="fas fa-link"></i></a>可视化 TensorBoard</h3>
      <ul>
<li>数据序列化-event 文件<ul>
<li><code>tf.summary.FileWriter(path, graph=sess.graph)</code></li>
</ul>
</li>
<li>启动 TensorBorad<ul>
<li>cmd 运行</li>
<li><code>tensorboard --logdir=./tmp/summary --host=127.0.0.1</code></li>
<li><img src="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200305181919.png"></li>
</ul>
</li>
</ul>

        <h3 id="OP"   >
          <a href="#OP" class="heading-link"><i class="fas fa-link"></i></a>OP</h3>
      <ul>
<li>数据：Tensor 对象</li>
<li>操作：Operation 对象</li>
</ul>

        <h2 id="会话"   >
          <a href="#会话" class="heading-link"><i class="fas fa-link"></i></a>会话</h2>
      <ul>
<li><code>tf.Session</code>：用于完整的程序当中</li>
<li><code>tf.InteractiveSession</code>：用于交互式上下文中的 TensorFlow，例如 shell</li>
<li>使用<code>a.eval()</code></li>
</ul>
<ul>
<li><p>会话资源需要回收</p>
<ul>
<li>直接使用<code>with</code></li>
</ul>
</li>
<li><p>初始化会话参数</p>
<ul>
<li><p>target：如果将此参数留空，会话将仅仅使用本地计算机中的设备。可以指定<code>grpc://</code>网址，以便指定 TensorFlow 服务器的地址，这使得会话可以访问该服务器控制的计算机上的所有设备。</p>
</li>
<li><p>graph：默认情况下，新的<code>tf.Session</code>将绑定到当前的默认图</p>
</li>
<li><p>config：此参数允许指定一个<code>tf.ConfigProto</code>以便控制会话的行为。例如，ConfigProto 协议用于打印设备使用信息</p>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session(config=tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>, log_device_placement=<span class="literal">True</span>)) <span class="keyword">as</span> sess:</span><br><span class="line"></span><br><span class="line"><span class="comment"># Device mapping: no known devices.</span></span><br><span class="line"><span class="comment"># add: (Add): /job:localhost/replica:0/task:0/device:CPU:0</span></span><br><span class="line"><span class="comment"># Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0</span></span><br><span class="line"><span class="comment"># Const_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0</span></span><br></pre></td></tr></table></div></figure>

<ul>
<li><p><code>run(fetches, feed_dict=None)</code></p>
<ul>
<li><p>通过使用<code>sess.run()</code>来运行 operation</p>
</li>
<li><p>fetches：单一的 operation，或者列表、元组（其他不属于 tensorflow 的类型不行）</p>
</li>
<li><p>feed_dict：参数允许调用者覆盖图中张量的值，运行时赋值</p>
<ul>
<li>与<code>tf.placeholder</code>搭配使用，则会检查值的形状是否与占位符兼容</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">	<span class="comment"># 查看c_t的值</span></span><br><span class="line">    <span class="built_in">print</span>(c_t.<span class="built_in">eval</span>())</span><br><span class="line">    <span class="built_in">print</span>(sess.run(c_t))</span><br><span class="line">    <span class="comment"># 查看a，b，c的值</span></span><br><span class="line">    <span class="built_in">print</span>([a, b ,c])</span><br></pre></td></tr></table></div></figure>

<ul>
<li>feed_dict 操作</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">session_run_demo</span>():</span></span><br><span class="line">    <span class="comment"># 定义占位符</span></span><br><span class="line">    a = tf.placeholder(tf.float32)</span><br><span class="line">    b = tf.placeholder(tf.float32)</span><br><span class="line">    sum_ab = tf.add(a, b)</span><br><span class="line">    <span class="comment"># 开启会话</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="built_in">print</span>(sess.run(sum_ab, feed_fict=&#123;a:<span class="number">3.0</span>, b:<span class="number">4.0</span>&#125;))</span><br></pre></td></tr></table></div></figure>


        <h2 id="张量"   >
          <a href="#张量" class="heading-link"><i class="fas fa-link"></i></a>张量</h2>
      
        <h3 id="数据类型"   >
          <a href="#数据类型" class="heading-link"><i class="fas fa-link"></i></a>数据类型</h3>
      <ul>
<li>张量如何存储<ul>
<li>标量 一个数字 0 阶张量 <code>shape()</code></li>
<li>向量 一维数组 1 阶张量 <code>shape(n,)</code>n 为数组长度</li>
<li>矩阵 二维数组 2 阶张量 <code>shape(n, m, )</code>n 行，m 列</li>
<li>张量 n 维数组 n 阶张量</li>
</ul>
</li>
<li>默认 tf.float32<ul>
<li>整型 tf.int32</li>
<li>浮点型 tf.float32</li>
</ul>
</li>
</ul>

        <h3 id="创建张量指令"   >
          <a href="#创建张量指令" class="heading-link"><i class="fas fa-link"></i></a>创建张量指令</h3>
      
        <h3 id="张量的变换"   >
          <a href="#张量的变换" class="heading-link"><i class="fas fa-link"></i></a>张量的变换</h3>
      <ul>
<li><p>类型的修改</p>
<ul>
<li><code>ndarry.astype(type)</code><ul>
<li><code>tf.cast(tensor, dtype)</code></li>
<li>不会改变原始的 tensor</li>
<li>返回新的 tensor</li>
</ul>
</li>
<li><code>ndarry.tostring()</code></li>
</ul>
</li>
<li><p>形状的修改</p>
<ul>
<li><p><code>ndarray.reshape(shape)</code>行变成列，列变成行</p>
</li>
<li><p><code>ndarray.resize(shape)</code></p>
</li>
<li><p>静态形状：初始创建张量时形状</p>
<ul>
<li><code>tensor.set_shape()</code></li>
<li>只有在形状没有完全固定下来的情况下，才能改变</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = tf.placeholder(dtype=tf.float32, shape=[<span class="literal">None</span>, <span class="literal">None</span>])</span><br><span class="line">b = tf.placeholder(dtype=tf.float32, shape=[<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line">c = tf.placeholder(dtype=tf.float32, shape=[<span class="number">10</span>, <span class="number">20</span>])</span><br><span class="line"><span class="comment"># a Tensor(&quot;Placeholder:0&quot;, shape=(?, ?), dtype=float32)</span></span><br><span class="line"><span class="comment"># b Tensor(&quot;Placeholder_1:0&quot;, shape=(?, 10), dtype=float32)</span></span><br><span class="line"><span class="comment"># c Tensor(&quot;Placeholder_2:0&quot;, shape=(10, 20), dtype=float32)</span></span><br><span class="line"></span><br><span class="line">a.set_shape([<span class="number">2</span>, <span class="number">3</span>]) <span class="comment"># a可以设置不同行列</span></span><br><span class="line">b.set_shape([<span class="number">2</span>, <span class="number">10</span>]) <span class="comment"># b只可以设置行，列已固定</span></span><br><span class="line"><span class="comment"># c不可设置，因为行列以固定</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># a Tensor(&quot;Placeholder:0&quot;, shape=(2, 3), dtype=float32)</span></span><br><span class="line"><span class="comment"># b Tensor(&quot;Placeholder_1:0&quot;, shape=(2, 10)</span></span><br></pre></td></tr></table></div></figure>

<ul>
<li><p>动态形状：</p>
<ul>
<li><p><code>tensor.reshape(tensor, shape)</code></p>
</li>
<li><p>不会改变原始 tensor，只会返回一个新的 tensor</p>
</li>
<li><p>必须保持张量的元素数量前后一致</p>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.placeholder(dtype=tf.float32, shape=[<span class="literal">None</span>, <span class="literal">None</span>])</span><br><span class="line">a.set_shape([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.reshape(a, shape=[<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>]))</span><br><span class="line"><span class="comment"># 变化后的元素数量等于原来的，2*3*1=2*3</span></span><br></pre></td></tr></table></div></figure>


        <h3 id="张量的数学公式"   >
          <a href="#张量的数学公式" class="heading-link"><i class="fas fa-link"></i></a>张量的数学公式</h3>
      <p>参考官方 api</p>
<ul>
<li>基本运算符</li>
<li>基本数学函数</li>
<li>矩阵运算</li>
<li>reduce 操作</li>
<li>序列索引操作</li>
</ul>

        <h2 id="变量-OP"   >
          <a href="#变量-OP" class="heading-link"><i class="fas fa-link"></i></a>变量 OP</h2>
      <p>TensorFlow 中的变量</p>
<ul>
<li>存储持久化</li>
<li>可修改值</li>
<li>可指定被训练</li>
</ul>

        <h3 id="创建变量"   >
          <a href="#创建变量" class="heading-link"><i class="fas fa-link"></i></a>创建变量</h3>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.Variable(initial_value=<span class="literal">None</span>, trainable=<span class="literal">True</span>, collections=<span class="literal">None</span>,)</span><br></pre></td></tr></table></div></figure>

<ul>
<li>initial_value：初始化的值</li>
<li>trainable：是否被训练</li>
<li>collections：新变量将添加到列出的图的集合中 collections</li>
<li><strong>变量需要显式初始化，才能运行值</strong></li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">	sess.run(init)</span><br></pre></td></tr></table></div></figure>

<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">variable_demo</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    变量演示</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    a = tf.Variable(initial_value=<span class="number">50</span>, )</span><br><span class="line">    b = tf.Variable(initial_value=<span class="number">40</span>, )</span><br><span class="line">    c = tf.add(a, b)</span><br><span class="line">    <span class="built_in">print</span>(a)</span><br><span class="line">    <span class="built_in">print</span>(b)</span><br><span class="line">    <span class="built_in">print</span>(c)</span><br><span class="line">    <span class="comment"># 初始化变量</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(init)</span><br><span class="line">        a_t, b_t, c_t = sess.run([a, b, c])</span><br><span class="line">        <span class="built_in">print</span>(a_t, b_t, c_t)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    variable_demo()</span><br><span class="line"></span><br><span class="line"><span class="comment"># &lt;tf.Variable &#x27;Variable:0&#x27; shape=() dtype=int32_ref&gt;</span></span><br><span class="line"><span class="comment"># &lt;tf.Variable &#x27;Variable_1:0&#x27; shape=() dtype=int32_ref&gt;</span></span><br><span class="line"><span class="comment"># Tensor(&quot;Add:0&quot;, shape=(), dtype=int32)</span></span><br><span class="line"><span class="comment"># 50 40 90</span></span><br></pre></td></tr></table></div></figure>

<ul>
<li>命名空间修改，使结构更加清晰</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;test&#x27;</span>):</span><br><span class="line">    a = tf.Variable(initial_value=<span class="number">50</span>, )</span><br><span class="line">    b = tf.Variable(initial_value=<span class="number">40</span>, )</span><br><span class="line">    c = tf.add(a, b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &lt;tf.Variable &#x27;test/Variable:0&#x27; shape=() dtype=int32_ref&gt;</span></span><br><span class="line"><span class="comment"># &lt;tf.Variable &#x27;test/Variable_1:0&#x27; shape=() dtype=int32_ref&gt;</span></span><br><span class="line"><span class="comment"># Tensor(&quot;test/Add:0&quot;, shape=(), dtype=int32)</span></span><br><span class="line"><span class="comment"># 多出了一个test/</span></span><br></pre></td></tr></table></div></figure>


        <h2 id="高级-API"   >
          <a href="#高级-API" class="heading-link"><i class="fas fa-link"></i></a>高级 API</h2>
      
        <h3 id="基础-API"   >
          <a href="#基础-API" class="heading-link"><i class="fas fa-link"></i></a>基础 API</h3>
      <ul>
<li><code>tf.app</code><ul>
<li>相当于为 TensorFlow 进行的脚本提供一个 main 函数入口，可以定义脚本运行的 flags。</li>
</ul>
</li>
<li><code>tf.image</code><ul>
<li>图像处理操作，主要是颜色的变换、变形和图像的编码和解码</li>
</ul>
</li>
<li><code>tf.summary</code><ul>
<li>用来生成 TensorBoard 可用的统计日志，目前 summary 主要提供了 4 种类型：audio、image、histogram、scalar</li>
</ul>
</li>
<li><code>tf.python_io</code><ul>
<li>用来读写 TFRecords 文件</li>
</ul>
</li>
<li><code>tf.train</code><ul>
<li>提供了一些训练器，与<code>tf.nn</code>组合起来，实现一些网络的优化计算</li>
</ul>
</li>
<li><code>tf.nn</code><ul>
<li>提供了一些构建神经网络的底层函数。TensorFlow 构建网络的核心模块。其中包含了添加各种层的函数，比如添加卷积层、池化层等</li>
</ul>
</li>
</ul>

        <h3 id="高级-API-1"   >
          <a href="#高级-API-1" class="heading-link"><i class="fas fa-link"></i></a>高级 API</h3>
      <ul>
<li><code>tf.keras</code><ul>
<li>在于快速构建模型</li>
</ul>
</li>
<li><code>tf.layers</code><ul>
<li>以更高级的概念层来定义一个模型，类似<code>tf.keras</code></li>
</ul>
</li>
<li><code>tf.contrib</code><ul>
<li>提供计算图中的网络层、正则化、摘要操作，是构建计算图的高级操作，但是，包含不稳定和实验代码，可能以后 API 会变。</li>
</ul>
</li>
<li><code>tf.estimator</code><ul>
<li>相当于 Model+Training+Evaluate 的合体，在模块中，已经实现了几种简单的分类器和回归器，包括：Baseline、Learning 和 DNN。这里的 DNN 的网络，只是全连接网络，没有提供卷积之类的。</li>
</ul>
</li>
</ul>

        <h3 id="高级-API-图示"   >
          <a href="#高级-API-图示" class="heading-link"><i class="fas fa-link"></i></a>高级 API 图示</h3>
      <p><img src="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200308221528.jpg"></p>

        <h2 id="案例：实现线性回归"   >
          <a href="#案例：实现线性回归" class="heading-link"><i class="fas fa-link"></i></a>案例：实现线性回归</h2>
      
        <h3 id="API"   >
          <a href="#API" class="heading-link"><i class="fas fa-link"></i></a>API</h3>
      
        <h4 id="运算"   >
          <a href="#运算" class="heading-link"><i class="fas fa-link"></i></a>运算</h4>
      <ul>
<li>矩阵运算<ul>
<li><code>tf.matmul(x, w)</code></li>
</ul>
</li>
<li>平方<ul>
<li><code>tf.square(error)</code></li>
</ul>
</li>
<li>均值<ul>
<li><code>tf.reduce_mean(error)</code></li>
</ul>
</li>
</ul>

        <h4 id="梯度下降优化"   >
          <a href="#梯度下降优化" class="heading-link"><i class="fas fa-link"></i></a>梯度下降优化</h4>
      <ul>
<li><code>tf.train.GradientDescentOptimizer(learning_rate)</code><ul>
<li>梯度下降优化</li>
<li>learning_rate：学习率，一般为 0~1 之间比较小的值</li>
<li>method<ul>
<li><code>minimize(loss)</code></li>
</ul>
</li>
<li>return：梯度下降 op</li>
</ul>
</li>
</ul>

        <h3 id="线性回归原理"   >
          <a href="#线性回归原理" class="heading-link"><i class="fas fa-link"></i></a>线性回归原理</h3>
      <ul>
<li>构建模型<ul>
<li><code>y = w1x1 + w2x2 + ... + wnxn + b</code></li>
</ul>
</li>
<li>构造损失函数<ul>
<li>均方误差</li>
</ul>
</li>
<li>优化损失<ul>
<li>梯度下降</li>
</ul>
</li>
</ul>

        <h3 id="案例：线性回归的训练"   >
          <a href="#案例：线性回归的训练" class="heading-link"><i class="fas fa-link"></i></a>案例：线性回归的训练</h3>
      <ul>
<li>准备真实数据<ul>
<li>100 个样本</li>
<li>x：特征值 形状：（100, 1）</li>
<li>y_true：目标值 目标值：（100, 1）</li>
<li><code>y_true = 0.8x + 0.7</code></li>
</ul>
</li>
<li>假定 x 和 y 之间的关系满足<ul>
<li><code>y = kx + b</code></li>
<li>趋近于<code>k = 0.8 b = 0.7</code></li>
</ul>
</li>
<li>流程分析<ul>
<li><code>(100, 1) * (1, 1) = (100, 1)</code></li>
<li><code>y_predict = x * weights(1, 1) + bias(1, 1)</code><ul>
<li>bias 可以是标量，也可以是向量</li>
</ul>
</li>
<li>构建模型<ul>
<li><code>y_predict = tf.matmul(x, weights) + bias</code></li>
</ul>
</li>
<li>构造损失函数<ul>
<li><code>error = tf.reduce_mean(tf.square(y_predict - y_true))</code></li>
</ul>
</li>
<li>优化损失<ul>
<li><code>optimizer= tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(error)</code></li>
<li>学习率会影响迭代训练次数</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_regression</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    实现线性回归</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1、准备数据</span></span><br><span class="line">    x = tf.random_normal(shape=[<span class="number">100</span>, <span class="number">1</span>])</span><br><span class="line">    y_true = tf.matmul(x, [[<span class="number">0.8</span>]]) + <span class="number">0.7</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2、构造模型</span></span><br><span class="line">    <span class="comment"># 定义模型参数，用变量</span></span><br><span class="line">    weights = tf.Variable(initial_value=tf.random_normal(shape=[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line">    bias = tf.Variable(initial_value=tf.random_normal(shape=[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line">    y_predict = tf.matmul(x, weights) + bias</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3、构造损失函数</span></span><br><span class="line">    error = tf.reduce_mean(tf.square(y_predict - y_true))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4、优化损失</span></span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.01</span>).minimize(error)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显式的初始化变量</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line">    <span class="comment"># 开启会话</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(init)</span><br><span class="line">        <span class="comment"># 查看初始化模型参数之后的值</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;训练前模型参数：权重%f，偏置%f，损失%f&#x27;</span> % (weights.<span class="built_in">eval</span>(), bias.<span class="built_in">eval</span>(), error.<span class="built_in">eval</span>()))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 开始训练</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">            <span class="comment"># 迭代1000次训练</span></span><br><span class="line">            sess.run(optimizer)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;训练后模型参数：权重%f，偏置%f，损失%f&#x27;</span> % (weights.<span class="built_in">eval</span>(), bias.<span class="built_in">eval</span>(), error.<span class="built_in">eval</span>()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    linear_regression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练前模型参数：权重-3.123351，偏置-0.332511，损失15.018922</span></span><br><span class="line"><span class="comment"># 训练后模型参数：权重0.799999，偏置0.699999，损失0.000000</span></span><br></pre></td></tr></table></div></figure>


        <h3 id="增加其他功能"   >
          <a href="#增加其他功能" class="heading-link"><i class="fas fa-link"></i></a>增加其他功能</h3>
      <ul>
<li>增加 TensorBoard 显示</li>
<li>增加命名空间</li>
<li>模型保存与加载</li>
<li>命令行参数设置</li>
</ul>

        <h4 id="增加变量显示"   >
          <a href="#增加变量显示" class="heading-link"><i class="fas fa-link"></i></a>增加变量显示</h4>
      <p>目的：在 TensorBoard 中观察模型的参数、损失值等变量值的变化</p>
<ul>
<li><p>创建事件文件</p>
</li>
<li><p>收集变量</p>
<ul>
<li><code>tf.summary.scalar(name=&#39;&#39;, tensor)</code>，收集对于损失函数和准确率等单值变量，name 为变量的名字，tensor 为值</li>
<li><code>tf.summary.histogram(name=&#39;&#39;, tensor)</code>，收集高纬度的变量参数</li>
<li><code>tf.summary.image(name=&#39;&#39;, tensor)</code>，收集输入的图片张量显示图片</li>
</ul>
</li>
<li><p>合并变量写入事件文件</p>
<ul>
<li><code>merged = tf.summary.merge_all()</code></li>
<li>运行合并：<code>summary = sess.sun(merged)</code>，每次迭代都需运行</li>
<li>添加：<code>FileWriter.add_summary(summary, i)</code>，i 表示第几次的值</li>
</ul>
</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_regression</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    实现线性回归</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1、准备数据</span></span><br><span class="line">    x = tf.random_normal(shape=[<span class="number">100</span>, <span class="number">1</span>])</span><br><span class="line">    y_true = tf.matmul(x, [[<span class="number">0.8</span>]]) + <span class="number">0.7</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2、构造模型</span></span><br><span class="line">    <span class="comment"># 定义模型参数，用变量</span></span><br><span class="line">    weights = tf.Variable(initial_value=tf.random_normal(shape=[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line">    bias = tf.Variable(initial_value=tf.random_normal(shape=[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line">    y_predict = tf.matmul(x, weights) + bias</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3、构造损失函数</span></span><br><span class="line">    error = tf.reduce_mean(tf.square(y_predict - y_true))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4、优化损失</span></span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.01</span>).minimize(error)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1_收集变量</span></span><br><span class="line">    tf.summary.scalar(<span class="string">&#x27;error&#x27;</span>, error)</span><br><span class="line">    tf.summary.histogram(<span class="string">&#x27;weights&#x27;</span>, weights)</span><br><span class="line">    tf.summary.histogram(<span class="string">&#x27;bias&#x27;</span>, bias)</span><br><span class="line">    <span class="comment"># 2_合并变量</span></span><br><span class="line">    merged = tf.summary.merge_all()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显式的初始化变量</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line">    <span class="comment"># 开启会话</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(init)</span><br><span class="line">        <span class="comment"># 查看初始化模型参数之后的值</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 0_创建事件文件</span></span><br><span class="line">        file_writer = tf.summary.FileWriter(<span class="string">&#x27;./tmp/liner&#x27;</span>, graph=sess.graph)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;训练前模型参数：权重%f，偏置%f，损失%f&#x27;</span> % (weights.<span class="built_in">eval</span>(), bias.<span class="built_in">eval</span>(), error.<span class="built_in">eval</span>()))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 开始训练</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">            <span class="comment"># 迭代1000次训练</span></span><br><span class="line">            sess.run(optimizer)</span><br><span class="line">            <span class="comment"># 3_运行合并变量操作</span></span><br><span class="line">            summary = sess.run(merged)</span><br><span class="line">            <span class="comment"># 4_将每次迭代后的变量写入事件文件</span></span><br><span class="line">            file_writer.add_summary(summary, i)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;训练后模型参数：权重%f，偏置%f，损失%f&#x27;</span> % (weights.<span class="built_in">eval</span>(), bias.<span class="built_in">eval</span>(), error.<span class="built_in">eval</span>()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    linear_regression()</span><br><span class="line"></span><br></pre></td></tr></table></div></figure>

<p><img src="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309190938.png"></p>
<p><img src="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309191005.png"></p>
<p><img src="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309191030.png"></p>
<p><img src="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309191053.png"></p>

        <h4 id="增加命名空间"   >
          <a href="#增加命名空间" class="heading-link"><i class="fas fa-link"></i></a>增加命名空间</h4>
      <ul>
<li><code>with tf.variable_scope(&#39;&#39;)</code></li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;prepare_data&#x27;</span>):</span><br><span class="line">    <span class="comment"># 1、准备数据</span></span><br><span class="line">    x = tf.random_normal(shape=[<span class="number">100</span>, <span class="number">1</span>], name=<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">    y_true = tf.matmul(x, [[<span class="number">0.8</span>]]) + <span class="number">0.7</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;create_mode&#x27;</span>):</span><br><span class="line">    <span class="comment"># 2、构造模型</span></span><br><span class="line">    <span class="comment"># 定义模型参数，用变量</span></span><br><span class="line">    weights = tf.Variable(initial_value=tf.random_normal(shape=[<span class="number">1</span>, <span class="number">1</span>]), name=<span class="string">&#x27;Weights&#x27;</span>)</span><br><span class="line">    bias = tf.Variable(initial_value=tf.random_normal(shape=[<span class="number">1</span>, <span class="number">1</span>]), name=<span class="string">&#x27;Bias&#x27;</span>)</span><br><span class="line">    y_predict = tf.matmul(x, weights) + bias</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;loss_fun&#x27;</span>):</span><br><span class="line">    <span class="comment"># 3、构造损失函数</span></span><br><span class="line">    error = tf.reduce_mean(tf.square(y_predict - y_true))</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;optimizer&#x27;</span>):</span><br><span class="line">    <span class="comment"># 4、优化损失</span></span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.01</span>).minimize(error)</span><br></pre></td></tr></table></div></figure>

<p><img src="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309191853.png"></p>
<p><img src="https://raw.githubusercontent.com/Pandalzy/cloud_img/master/img/blog20200309191942.png"></p>

        <h4 id="模型的保存与加载"   >
          <a href="#模型的保存与加载" class="heading-link"><i class="fas fa-link"></i></a>模型的保存与加载</h4>
      <ul>
<li><code>tf.train.Saver(var_list=None, max_to_keep=5)</code><ul>
<li>保存和加载模型（文件格式：checkpoint 文件）</li>
<li>var_list：指定将要保存和还原的变量，它可以作为一个 dict 或一个列表传递</li>
<li>max_to_keep：指示要保留的最近检查点文件的最大数量。创建新文件时，会删除较旧的文件。如果无或 0，则保留所有检查点文件。默认为 5（即保留最新的 5 个检查点文件）</li>
</ul>
</li>
<li>步骤<ul>
<li>实例化 Saver，<code>saver = tf.train.Saver(var_list=None, max_to_keep=5)</code></li>
<li>保存，<code>saver.save(sess, path)</code><ul>
<li>路径需存在</li>
<li>例：<code>saver.save(sess, &#39;/tmp/ckpt/test/myregression.ckpt&#39;)</code></li>
</ul>
</li>
<li>加载，<code>saver.restore(sess, path)</code><ul>
<li>例：<code>saver.restore(sess, &#39;/tmp/ckpt/test/myregression.ckpt&#39;)</code></li>
</ul>
</li>
</ul>
</li>
</ul>

        <h4 id="命令行参数使用"   >
          <a href="#命令行参数使用" class="heading-link"><i class="fas fa-link"></i></a>命令行参数使用</h4>
      <ul>
<li><code>tf.app.flags</code><ul>
<li><code>tf.app.flags.DEFINE_integer(&#39;max_step&#39;, 0, &#39;训练模型的步数&#39;)</code><ul>
<li>参数<code>(flag_name, default_value, docstring)</code></li>
</ul>
</li>
<li><code>tf.app.flags.DEFINE_string(flag_name, default_value, docstring)</code></li>
<li><code>tf.app.flags.DEFINE_boolean(flag_name, default_value, docstring)</code></li>
<li><code>tf.app.flags.DEFINE_float(flag_name, default_value, docstring)</code></li>
</ul>
</li>
<li>在 flags 有一个 FLAGS 标志，它在程序中可以调用到前面具体定义的 flag_name<ul>
<li><code>FLAGS = tf.app.flags.FLAGS</code></li>
<li>通过<code>FLAGS.max_step</code>调用命令行中传过来的参数</li>
</ul>
</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">&#x27;max_step&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;训练模型的步数&#x27;</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">&#x27;model_dir&#x27;</span>, <span class="string">&#x27;Unknown&#x27;</span>, <span class="string">&#x27;模型路径+名字&#x27;</span>)</span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">command_demo</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    命令行演示</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(FLAGS.max_step)</span><br><span class="line">    <span class="built_in">print</span>(FLAGS.model_dir)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    command_demo()</span><br></pre></td></tr></table></div></figure>

<figure class="highlight shell"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">python day01_deeplearning.py</span></span><br><span class="line">0</span><br><span class="line">Unknown</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">python day01_deeplearning.py --max_step=200 --model_dir=<span class="string">&#x27;/tmp/t.txt&#x27;</span></span></span><br><span class="line">200</span><br><span class="line">&#x27;/tmp/t.txt&#x27;</span><br></pre></td></tr></table></div></figure>

<ul>
<li>通过<code>tf.app.run()</code>启动<code>main(argv)</code>函数</li>
</ul>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">argv</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(argv)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tf.app.run()</span><br><span class="line"></span><br><span class="line"><span class="comment"># [&#x27;C:/Users/yuan/PycharmProjects/tensor/day01_deeplearning.py&#x27;]</span></span><br><span class="line"><span class="comment"># 当前py文件所在目录</span></span><br></pre></td></tr></table></div></figure>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="https://blog.zyuanlee.cn">Pandalzy</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="https://blog.zyuanlee.cn/2020/03/09/TensorFlow%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D/">https://blog.zyuanlee.cn/2020/03/09/TensorFlow%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://blog.zyuanlee.cn/tags/TensorFlow/">TensorFlow</a></span><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://blog.zyuanlee.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2020/03/14/TensorFlow%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E3%80%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">TensorFlow数据读取、神经网络</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2020/03/08/mysql%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/"><span class="paginator-prev__text">mysql的一些知识</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#TF-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%9B%BE"><span class="toc-number">1.</span> <span class="toc-text">
          TF 数据流图</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E6%B3%95%E6%A1%88%E4%BE%8B"><span class="toc-number">1.1.</span> <span class="toc-text">
          加法案例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TF-%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90"><span class="toc-number">1.2.</span> <span class="toc-text">
          TF 结构分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B5%81%E5%9B%BE%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.1.</span> <span class="toc-text">
          数据流图介绍</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E4%B8%8E-TensorBoard"><span class="toc-number">2.</span> <span class="toc-text">
          图与 TensorBoard</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%BE%E7%BB%93%E6%9E%84"><span class="toc-number">2.1.</span> <span class="toc-text">
          图结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C"><span class="toc-number">2.2.</span> <span class="toc-text">
          相关操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96-TensorBoard"><span class="toc-number">2.3.</span> <span class="toc-text">
          可视化 TensorBoard</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#OP"><span class="toc-number">2.4.</span> <span class="toc-text">
          OP</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%9A%E8%AF%9D"><span class="toc-number">3.</span> <span class="toc-text">
          会话</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%A0%E9%87%8F"><span class="toc-number">4.</span> <span class="toc-text">
          张量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.1.</span> <span class="toc-text">
          数据类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%BC%A0%E9%87%8F%E6%8C%87%E4%BB%A4"><span class="toc-number">4.2.</span> <span class="toc-text">
          创建张量指令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%A0%E9%87%8F%E7%9A%84%E5%8F%98%E6%8D%A2"><span class="toc-number">4.3.</span> <span class="toc-text">
          张量的变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F"><span class="toc-number">4.4.</span> <span class="toc-text">
          张量的数学公式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%98%E9%87%8F-OP"><span class="toc-number">5.</span> <span class="toc-text">
          变量 OP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%8F%98%E9%87%8F"><span class="toc-number">5.1.</span> <span class="toc-text">
          创建变量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E7%BA%A7-API"><span class="toc-number">6.</span> <span class="toc-text">
          高级 API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80-API"><span class="toc-number">6.1.</span> <span class="toc-text">
          基础 API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E7%BA%A7-API-1"><span class="toc-number">6.2.</span> <span class="toc-text">
          高级 API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E7%BA%A7-API-%E5%9B%BE%E7%A4%BA"><span class="toc-number">6.3.</span> <span class="toc-text">
          高级 API 图示</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%EF%BC%9A%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">7.</span> <span class="toc-text">
          案例：实现线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#API"><span class="toc-number">7.1.</span> <span class="toc-text">
          API</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%90%E7%AE%97"><span class="toc-number">7.1.1.</span> <span class="toc-text">
          运算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%BC%98%E5%8C%96"><span class="toc-number">7.1.2.</span> <span class="toc-text">
          梯度下降优化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86"><span class="toc-number">7.2.</span> <span class="toc-text">
          线性回归原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E8%AE%AD%E7%BB%83"><span class="toc-number">7.3.</span> <span class="toc-text">
          案例：线性回归的训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A2%9E%E5%8A%A0%E5%85%B6%E4%BB%96%E5%8A%9F%E8%83%BD"><span class="toc-number">7.4.</span> <span class="toc-text">
          增加其他功能</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A2%9E%E5%8A%A0%E5%8F%98%E9%87%8F%E6%98%BE%E7%A4%BA"><span class="toc-number">7.4.1.</span> <span class="toc-text">
          增加变量显示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A2%9E%E5%8A%A0%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4"><span class="toc-number">7.4.2.</span> <span class="toc-text">
          增加命名空间</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD"><span class="toc-number">7.4.3.</span> <span class="toc-text">
          模型的保存与加载</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E4%BD%BF%E7%94%A8"><span class="toc-number">7.4.4.</span> <span class="toc-text">
          命令行参数使用</span></a></li></ol></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/assets/avatar.jpg" alt="avatar"></div><p class="sidebar-ov-author__text">Stay hungry, stay foolish.</p></div><div class="sidebar-ov-social"></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">45</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">7</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">31</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Pandalzy</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v5.4.0</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.1.1</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><div class="search-mask"></div><div class="search-popup"><span class="search-close"></span><div class="search-input"><input placeholder="搜索文章（支持多关键词，请用空格分隔）"></div><div class="search-results"></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script>function initSearch() {
  var isXML = true;
  var search_path = 'search.xml';

  if (!search_path) {
    search_path = 'search.xml';
  } else if (/json$/i.test(search_path)) {
    isXML = false;
  }

  var path = '/' + search_path;
  $.ajax({
    url: path,
    dataType: isXML ? 'xml' : 'json',
    async: true,
    success: function (res) {
      var datas = isXML ? $('entry', res).map(function () {
        // 将 XML 转为 JSON
        return {
          title: $('title', this).text(),
          content: $('content', this).text(),
          url: $('url', this).text()
        };
      }).get() : res;
      var $input = $('.search-input input');
      var $result = $('.search-results');
      // 搜索对象（标题、内容）的权重，影响显示顺序
      var WEIGHT = { title: 100, content: 1 };
      var searchPost = function () {
        var searchText = $input.val().toLowerCase().trim();
        // 根据空白字符分隔关键字
        var keywords = searchText.split(/[\s]+/);
        // 搜索结果
        var matchPosts = [];

        // 有多个关键字时，将原文字整个保存下来
        if (keywords.length > 1) {
          keywords.push(searchText);
        }
        // 防止未输入字符时搜索
        if (searchText.length > 0) {
          datas.forEach(function (data) {
            var isMatch  = false;
            // 没有标题的文章使用预设的 i18n 变量代替
            var title = (data.title && data.title.trim()) || '[ 文章无标题 ]';
            var titleLower = title && title.toLowerCase();
            // 删除 HTML 标签 和 所有空白字符
            var content = data.content && data.content.replace(/<[^>]+>/g, '');
            var contentLower = content && content.toLowerCase();
            // 删除重复的 /
            var postURL = data.url && decodeURI(data.url).replace(/\/{2,}/g, '/');
            // 标题中匹配到的关键词
            var titleHitSlice = [];
            // 内容中匹配到的关键词
            var contentHitSlice = [];

            keywords.forEach(function (keyword) {
              /**
              * 获取匹配的关键词的索引
              * @param {String} keyword 要匹配的关键字
              * @param {String} text 原文字
              * @param {Boolean} caseSensitive 是否区分大小写
              * @param {Number} weight 匹配对象的权重。权重大的优先显示
              * @return {Array}
              */
              function getIndexByword (word, text, caseSensitive, weight) {
                if (!word || !text) {
                  return [];
                };

                var startIndex = 0; // 每次匹配的开始索引
                var index = -1;     // 匹配到的索引值
                var result = [];    // 匹配结果

                if (!caseSensitive) {
                  word = word.toLowerCase();
                  text = text.toLowerCase();
                }

                while((index = text.indexOf(word, startIndex)) !== -1) {
                  var hasMatch = false;
                  // 索引位置相同的关键词，保留长度较长的
                  titleHitSlice.forEach(function (hit) {
                    if (hit.index === index && hit.word.length < word.length) {
                      hit.word = word;
                      hasMatch = true;
                    }
                  });
                  startIndex = index + word.length;
                  !hasMatch && result.push({ index: index, word: word, weight: weight });
                }
                return result;
              }
              titleHitSlice = titleHitSlice.concat(getIndexByword(keyword, titleLower, false, WEIGHT.title));
              contentHitSlice = contentHitSlice.concat(getIndexByword(keyword, contentLower, false, WEIGHT.content));
            });

            var hitTitle = titleHitSlice.length;
            var hitContent = contentHitSlice.length;

            if (hitTitle > 0 || hitContent > 0) {
              isMatch = true;
            }
            if (isMatch) {
              ;[titleHitSlice, contentHitSlice].forEach(function (hit) {
                // 按照匹配文字的索引的递增顺序排序
                hit.sort(function (left, right) {
                  return left.index - right.index;
                });
              });
              /**
              * 给文本中匹配到的关键词添加标记，从而进行高亮显示
              * @param {String} text 原文本
              * @param {Array} hitSlice 匹配项的索引信息
              * @param {Number} start 开始索引
              * @param {Number} end 结束索引
              * @return {String}
              */
              function highlightKeyword (text, hitSlice, start, end) {
                if (!text || !hitSlice || !hitSlice.length) {
                  return;
                }

                var result = '';
                var startIndex = start;
                var endIndex = end;
                hitSlice.forEach(function (hit) {
                  if (hit.index < startIndex) {
                    return;
                  }

                  var hitWordEnd = hit.index + hit.word.length;
                  result += text.slice(startIndex, hit.index);
                  result += '<b>' + text.slice(hit.index, hitWordEnd) + '</b>';
                  startIndex = hitWordEnd;
                });
                result += text.slice(startIndex, endIndex);
                return result;
              }

              var postData = {};
              // 文章总的搜索权重
              var postWeight = titleHitSlice.length * WEIGHT.title + contentHitSlice.length * WEIGHT.content;
              // 标记匹配关键词后的标题
              var postTitle = highlightKeyword(title, titleHitSlice, 0, title.length) || title;
              // 标记匹配关键词后的内容
              var postContent;
              // 显示内容的长度
              var SHOW_WORD_LENGTH = 200;
              // 命中关键词前的字符显示长度
              var SHOW_WORD_FRONT_LENGTH = 20;
              var SHOW_WORD_END_LENGTH = SHOW_WORD_LENGTH - SHOW_WORD_FRONT_LENGTH;

              // 截取匹配的第一个字符，前后共 200 个字符来显示
              if (contentHitSlice.length > 0) {
                var firstIndex = contentHitSlice[0].index;
                var start = firstIndex > SHOW_WORD_FRONT_LENGTH ? firstIndex - SHOW_WORD_FRONT_LENGTH : 0;
                var end = firstIndex + SHOW_WORD_END_LENGTH;
                postContent = highlightKeyword(content, contentHitSlice, start, end);
              } else { // 未匹配到内容，直接截取前 200 个字符来显示
                postContent = content.slice(0, SHOW_WORD_LENGTH);
              }
              postData.title = postTitle;
              postData.content = postContent;
              postData.url = postURL;
              postData.weight = postWeight;
              matchPosts.push(postData);
            }
          });
        }

        var resultInnerHtml = '';
        if (matchPosts.length) {
          // 按权重递增的顺序排序，使权重大的优先显示
          matchPosts.sort(function (left, right) {
            return right.weight - left.weight;
          });
          resultInnerHtml += '<ul>';
          matchPosts.forEach(function (post) {
            resultInnerHtml += '<li><a class="search-results-title" href="' + post.url + '">';
            resultInnerHtml += post.title;
            resultInnerHtml += '</a><div class="search-results-content">';
            resultInnerHtml += post.content;
            resultInnerHtml += '</div></li>';
          });
          resultInnerHtml += '</ul>';
        } else {
          resultInnerHtml += '<div class="search-results-none"><i class="far fa-meh"></i></div>';
        }
        $result.html(resultInnerHtml);
      };
      $input.on('input', searchPost);
      $input.on('keyup', function (e) {
        if (e.keyCode === Stun.utils.codeToKeyCode('Enter')) {
          searchPost();
        }
      });
    }
  });
}

function closeSearch () {
  $('body').css({ overflow: 'auto' });
  $('.search-popup').css({ display: 'none' });
  $('.search-mask').css({ display: 'none' });
}

window.addEventListener('DOMContentLoaded', function () {
  Stun.utils.pjaxReloadLocalSearch = function () {
    $('.header-nav-search').on('click', function (e) {
      e.stopPropagation();
      $('body').css('overflow', 'hidden');
      $('.search-popup')
        .velocity('stop')
        .velocity('transition.expandIn', {
          duration: 300,
          complete: function () {
            $('.search-popup input').focus();
          }
        });
      $('.search-mask')
        .velocity('stop')
        .velocity('transition.fadeIn', {
          duration: 300
        });

      initSearch();
    });
    $('.search-mask, .search-close').on('click', function () {
      closeSearch();
    });
    $(document).on('keydown', function (e) {
      // Escape <=> 27
      if (e.keyCode === Stun.utils.codeToKeyCode('Escape')) {
        closeSearch();
      }
    });
  };

  Stun.utils.pjaxReloadLocalSearch();
}, false);</script><script src="/js/utils.js?v=2.1.1"></script><script src="/js/stun-boot.js?v=2.1.1"></script><script src="/js/scroll.js?v=2.1.1"></script><script src="/js/header.js?v=2.1.1"></script><script src="/js/sidebar.js?v=2.1.1"></script><script type="application/json" src="/search.xml"></script></body></html>